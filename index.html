<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Derek Geng</title>

    <meta name="author" content="Derek Geng">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:85%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Derek Geng
                </p>
                <p>I am a third year undergraduate student at Princeton University studying Computer Science, pursuing minors in Robotics and Intelligent Systems, Statistics and Machine Learning, and Applied Math. I am currently a student researcher at <a href="https://pvl.cs.princeton.edu/">Princeton's Vision and Learning Lab</a>, led by <a href="https://www.cs.princeton.edu/~jiadeng/">Jia Deng</a>.
                </p>
                <p>
                 My research interests lie in studying artifical intellegence in robotics. I am interested in developing algorithms and methods for embodied intellegence, robot learning, and generalized perception. Within my current work I have experience in robotic grasping, developing imitation learning models for grasping in simulation and implementing grasping methods on Franka Emika R3 using ROS.
                </p>
                <p style="text-align:center">
                  <a href="mailto:derekgeng@princeton.edu">Email</a> &nbsp;/&nbsp;
                  <a href="data/Derek_Geng_Resume_Research.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?hl=en&user=8kK3XmYAAAAJ&view_op=list_works&gmla=AGd7smHnk8VzWwTos4Yi8Cuw3-xbKjUWqW2_y3izlTSo_6cGLMYkzIJY3hku73VuMGZZgvNx86CtVsOniQFVkqm7">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://github.com/derekgeng15/">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:37%;max-width:37%">
                <a href="images/headshot.jpeg"><img style="width:200%;max-width:200%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/headshot.jpeg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Research</h2>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>



    <tr onmouseout="r2r_stop()" onmouseover="r2r_start()">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='r2r_image'><video  width=100% muted autoplay loop>
          <source src="images/r2r.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/FetchBench.png' width=100%>
        </div>
        <script type="text/javascript">
          function r2r_start() {
            document.getElementById('r2r_image').style.opacity = "1";
          }

          function r2r_stop() {
            document.getElementById('r2r_image').style.opacity = "0";
          }
          r2r_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://github.com/princeton-vl/FetchBench-CORL2024">
          <span class="papertitle">FetchBench: A Simulation Benchmark for Robot Fetching</span>
        </a>
        <br>
        <a href="https://scholar.google.com/citations?user=LVjU7xIAAAAJ&hl=en">Beining Han</a>,
        <a href="https://scholar.google.com/citations?user=q38OfTQAAAAJ&hl=en">Meenal Parakh</a>,
				<strong>Derek Geng</strong>, 
        <a href="https://jackdefay.com/">Jack A Defay</a>,
        <a href="https://www.linkedin.com/in/gan-luyang-0956b8286/">Gan Luyang </a>, 
        <a href="https://www.cs.princeton.edu/~jiadeng/">Jia Deng</a>
        <br>
        <em>CoRL 2024</em>
        <br>
        <a href="https://github.com/princeton-vl/FetchBench-CORL2024">project page</a>
        /
        <a href="https://arxiv.org/abs/2406.11793">arXiv</a>
        <p></p>
        <p>
          Fetching, which includes approaching, grasping, and retrieving, is a critical challenge for robot manipulation tasks. Existing methods primarily focus on table-top scenarios, which do not adequately capture the complexities of environments where both grasping and planning are essential. To address this gap, we propose a new benchmark FetchBench, featuring diverse procedural scenes that integrate both grasping and motion planning challenges.
        </p>
      </td>
    </tr>
          
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:center;font-size:small;">
                  Website template from Jon Barron's website <a href="https://github.com/jonbarron/jonbarron_website">source code</a>
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
